{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1212)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\91858\\Desktop\\python\\mnist-in-csv\\mnist_train.csv')\n",
    "df_test = pd.read_csv(r'C:\\Users\\91858\\Desktop\\python\\mnist-in-csv\\mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_features = df_train.iloc[:, 1:785]\n",
    "df_label = df_train.iloc[:, 0]\n",
    "\n",
    "X_test = df_test.iloc[:, 0:784]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91858\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\91858\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\Users\\91858\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
    "                                                test_size = 0.25,\n",
    "                                                random_state = 1212)\n",
    "\n",
    "X_train = X_train.as_matrix().reshape(45000, 784) #(45000, 784)\n",
    "X_cv = X_cv.as_matrix().reshape(15000, 784) #(15000, 784)\n",
    "\n",
    "X_test = X_test.as_matrix().reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 254)\n"
     ]
    }
   ],
   "source": [
    "print((min(X_train[1]), max(X_train[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Normalization \n",
    "X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')\n",
    "X_train /= 255; X_cv /= 255; X_test /= 255\n",
    "\n",
    "# Convert labels to One Hot Encoded\n",
    "num_digits = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
    "y_cv = keras.utils.to_categorical(y_cv, num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Printing 2 examples of labels after conversion\n",
    "print(y_train[0]) # 2\n",
    "print(y_train[3]) # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model = Model(Inp, output)\n",
    "model.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Hyperparameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "sgd = optimizers.SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rely on the plain vanilla Stochastic Gradient Descent as our optimizing methodology\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 1.5993 - accuracy: 0.5708 - val_loss: 0.6925 - val_accuracy: 0.8155\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.4989 - accuracy: 0.8615 - val_loss: 0.3932 - val_accuracy: 0.8876\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.3546 - accuracy: 0.8994 - val_loss: 0.3217 - val_accuracy: 0.9045\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.3005 - accuracy: 0.9141 - val_loss: 0.2762 - val_accuracy: 0.9183\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.2656 - accuracy: 0.9235 - val_loss: 0.2484 - val_accuracy: 0.9263\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.2383 - accuracy: 0.9314 - val_loss: 0.2290 - val_accuracy: 0.9327\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.2178 - accuracy: 0.9371 - val_loss: 0.2100 - val_accuracy: 0.9368\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.1990 - accuracy: 0.9427 - val_loss: 0.1952 - val_accuracy: 0.9422\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.1833 - accuracy: 0.9470 - val_loss: 0.1815 - val_accuracy: 0.9455\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.1705 - accuracy: 0.9507 - val_loss: 0.1809 - val_accuracy: 0.9461\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.1584 - accuracy: 0.9541 - val_loss: 0.1605 - val_accuracy: 0.9522\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.1479 - accuracy: 0.9573 - val_loss: 0.1536 - val_accuracy: 0.9546\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.1387 - accuracy: 0.9598 - val_loss: 0.1502 - val_accuracy: 0.9557\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.1310 - accuracy: 0.9623 - val_loss: 0.1385 - val_accuracy: 0.9592\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.1233 - accuracy: 0.9643 - val_loss: 0.1362 - val_accuracy: 0.9604\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.1165 - accuracy: 0.9660 - val_loss: 0.1289 - val_accuracy: 0.9619\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.1100 - accuracy: 0.9685 - val_loss: 0.1254 - val_accuracy: 0.9631\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.1047 - accuracy: 0.9698 - val_loss: 0.1236 - val_accuracy: 0.9629\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0986 - accuracy: 0.9718 - val_loss: 0.1183 - val_accuracy: 0.9650\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0940 - accuracy: 0.9731 - val_loss: 0.1144 - val_accuracy: 0.9657\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "# We rely on ADAM as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2 = Model(Inp, output)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 0.2947 - accuracy: 0.9127 - val_loss: 0.1396 - val_accuracy: 0.9575\n",
      "Epoch 2/20\n",
      " - 3s - loss: 0.1081 - accuracy: 0.9670 - val_loss: 0.1062 - val_accuracy: 0.9677\n",
      "Epoch 3/20\n",
      " - 3s - loss: 0.0733 - accuracy: 0.9766 - val_loss: 0.0843 - val_accuracy: 0.9741\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.1016 - val_accuracy: 0.9711\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0939 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.0832 - val_accuracy: 0.9773\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.0963 - val_accuracy: 0.9741\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0997 - val_accuracy: 0.9757\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.0951 - val_accuracy: 0.9762\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0922 - val_accuracy: 0.9777\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0977 - val_accuracy: 0.9785\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.1174 - val_accuracy: 0.9731\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.1060 - val_accuracy: 0.9760\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0989 - val_accuracy: 0.9779\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.1007 - val_accuracy: 0.9773\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.1068 - val_accuracy: 0.9771\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0900 - val_accuracy: 0.9805\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.1036 - val_accuracy: 0.9785\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.1019 - val_accuracy: 0.9797\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.1285 - val_accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      verbose = 2,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2a = Model(Inp, output)\n",
    "\n",
    "model2a.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 0.2978 - accuracy: 0.9113 - val_loss: 0.1705 - val_accuracy: 0.9489\n",
      "Epoch 2/20\n",
      " - 3s - loss: 0.1124 - accuracy: 0.9663 - val_loss: 0.1017 - val_accuracy: 0.9689\n",
      "Epoch 3/20\n",
      " - 4s - loss: 0.0748 - accuracy: 0.9762 - val_loss: 0.0826 - val_accuracy: 0.9744\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.0910 - val_accuracy: 0.9750\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.0438 - accuracy: 0.9858 - val_loss: 0.0944 - val_accuracy: 0.9737\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.0845 - val_accuracy: 0.9763\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0995 - val_accuracy: 0.9727\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.0875 - val_accuracy: 0.9763\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0789 - val_accuracy: 0.9809\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0977 - val_accuracy: 0.9761\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0942 - val_accuracy: 0.9792\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.1052 - val_accuracy: 0.9769\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0955 - val_accuracy: 0.9782\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0866 - val_accuracy: 0.9807\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.1082 - val_accuracy: 0.9773\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0870 - val_accuracy: 0.9811\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0980 - val_accuracy: 0.9803\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0867 - val_accuracy: 0.9833\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1421 - val_accuracy: 0.9717\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.1110 - val_accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "history2a = model2a.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                        verbose = 2,\n",
    "                        validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.5\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2b = Model(Inp, output)\n",
    "\n",
    "model2b.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.3057 - accuracy: 0.9095 - val_loss: 0.1215 - val_accuracy: 0.9635\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.1107 - accuracy: 0.9666 - val_loss: 0.1250 - val_accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 3s 72us/step - loss: 0.0737 - accuracy: 0.9771 - val_loss: 0.0790 - val_accuracy: 0.9759\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 3s 72us/step - loss: 0.0514 - accuracy: 0.9840 - val_loss: 0.0892 - val_accuracy: 0.9748\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.0441 - accuracy: 0.9859 - val_loss: 0.0832 - val_accuracy: 0.9765\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 0.0887 - val_accuracy: 0.9765\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0880 - val_accuracy: 0.9776\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.1065 - val_accuracy: 0.9735\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0949 - val_accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 3s 69us/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0874 - val_accuracy: 0.9785\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 3s 69us/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0859 - val_accuracy: 0.9795\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.1292 - val_accuracy: 0.9733\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.1045 - val_accuracy: 0.9787\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 3s 72us/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0991 - val_accuracy: 0.9787\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 3s 72us/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.0923 - val_accuracy: 0.9829\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.1198 - val_accuracy: 0.9768\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0936 - val_accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 3s 72us/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.1030 - val_accuracy: 0.9797\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1027 - val_accuracy: 0.9783\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1025 - val_accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "history2b = model2b.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                            validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 100\n",
    "n_hidden_5 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_5 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 308,010\n",
      "Trainable params: 308,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '7' layers - input layer, 5 hidden layer and 1 output layer\n",
    "model3 = Model(Inp, output)\n",
    "model3.summary() # We have 308,010 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rely on 'Adam' as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.3054 - accuracy: 0.9077 - val_loss: 0.1350 - val_accuracy: 0.9583\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.1131 - accuracy: 0.9649 - val_loss: 0.1002 - val_accuracy: 0.9707\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.0757 - accuracy: 0.9762 - val_loss: 0.1076 - val_accuracy: 0.9680\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.1058 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0883 - val_accuracy: 0.9757\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0915 - val_accuracy: 0.9763\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 3s 73us/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 0.0913 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.1028 - val_accuracy: 0.9762\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.1089 - val_accuracy: 0.9741\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.1015 - val_accuracy: 0.9772\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.1161 - val_accuracy: 0.9730\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 4s 78us/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.0892 - val_accuracy: 0.9779\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0935 - val_accuracy: 0.9797\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.1200 - val_accuracy: 0.9722\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 4s 80us/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1169 - val_accuracy: 0.9742\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0962 - val_accuracy: 0.9796\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.1110 - val_accuracy: 0.9782\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1123 - val_accuracy: 0.9775\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0996 - val_accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model4 = Model(Inp, output)\n",
    "model4.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 5s 101us/step - loss: 0.5116 - accuracy: 0.8385 - val_loss: 0.1647 - val_accuracy: 0.9498\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.2165 - accuracy: 0.9380 - val_loss: 0.1178 - val_accuracy: 0.9647\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.1610 - accuracy: 0.9532 - val_loss: 0.0990 - val_accuracy: 0.9713\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 4s 80us/step - loss: 0.1317 - accuracy: 0.9613 - val_loss: 0.0925 - val_accuracy: 0.9735\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.1179 - accuracy: 0.9653 - val_loss: 0.0889 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.1071 - accuracy: 0.9690 - val_loss: 0.0895 - val_accuracy: 0.9760\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0909 - accuracy: 0.9729 - val_loss: 0.0894 - val_accuracy: 0.9750\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0862 - accuracy: 0.9746 - val_loss: 0.0817 - val_accuracy: 0.9791\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0783 - accuracy: 0.9771 - val_loss: 0.0831 - val_accuracy: 0.9779\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0762 - accuracy: 0.9765 - val_loss: 0.0800 - val_accuracy: 0.9779\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 0.0850 - val_accuracy: 0.9780\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0643 - accuracy: 0.9809 - val_loss: 0.0764 - val_accuracy: 0.9794\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.0839 - val_accuracy: 0.9790\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0582 - accuracy: 0.9824 - val_loss: 0.0786 - val_accuracy: 0.9801\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 4s 92us/step - loss: 0.0570 - accuracy: 0.9831 - val_loss: 0.0726 - val_accuracy: 0.9807\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0527 - accuracy: 0.9839 - val_loss: 0.0843 - val_accuracy: 0.9803\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 4s 89us/step - loss: 0.0512 - accuracy: 0.9852 - val_loss: 0.0778 - val_accuracy: 0.9797\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 4s 92us/step - loss: 0.0522 - accuracy: 0.9846 - val_loss: 0.0799 - val_accuracy: 0.9811\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 4s 88us/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 0.0696 - val_accuracy: 0.9827\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 4s 90us/step - loss: 0.0472 - accuracy: 0.9858 - val_loss: 0.0750 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = training_epochs,\n",
    "                    validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      7\n",
       "1        2      2\n",
       "2        3      1\n",
       "3        4      0\n",
       "4        5      4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(model4.predict(X_test, batch_size=200))\n",
    "test_pred = pd.DataFrame(test_pred.idxmax(axis = 1))\n",
    "test_pred.index.name = 'ImageId'\n",
    "test_pred = test_pred.rename(columns = {0: 'Label'}).reset_index()\n",
    "test_pred['ImageId'] = test_pred['ImageId'] + 1\n",
    "\n",
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv('mnist_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
